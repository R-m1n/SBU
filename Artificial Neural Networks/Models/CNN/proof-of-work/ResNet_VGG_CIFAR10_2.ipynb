{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "T0JhngkfFurR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v69C54SlV5ub",
        "outputId": "571ee8ab-4379-43f9-dd01-0446f17476ea"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    \n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print('Device:', device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ub0ok_w6FurT",
        "outputId": "fe615281-dcf6-4207-e8d1-8c4e442ab2c9"
      },
      "outputs": [],
      "source": [
        "class VGG16(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(VGG16, self).__init__()\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(25088, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Dropout(p=0.5),\n",
        "\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Dropout(p=0.5),\n",
        "\n",
        "            nn.Linear(4096, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        x = self.classifier(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "72WH4rzZVvJH"
      },
      "outputs": [],
      "source": [
        "def train_model(model, device, train_loader, val_loader, test_loader, num_epochs, optimizer, patience):\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    train_accs = []\n",
        "    val_accs = []\n",
        "\n",
        "    counter = 0\n",
        "    best_val_loss = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "\n",
        "        running_loss = 0.0\n",
        "        running_correct = 0\n",
        "\n",
        "        for batch_idx, (features, targets) in enumerate(train_loader):\n",
        "            features = features.to(device)\n",
        "            targets = targets.to(device)\n",
        "\n",
        "            outputs = model(features)\n",
        "            loss = F.cross_entropy(outputs, targets)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted_labels = torch.max(outputs, 1)\n",
        "            running_correct += (predicted_labels == targets).sum().item()\n",
        "\n",
        "            if not batch_idx % 50:\n",
        "                print(f\"Epoch: {epoch+1:02d}/{num_epochs:02d} | Mini-Batch {batch_idx:03d}/{len(train_loader):03d} | Loss: {loss:.4f}\")\n",
        "\n",
        "        train_loss = running_loss / len(train_loader)\n",
        "        train_acc = running_correct / len(train_loader)\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        train_accs.append(train_acc)\n",
        "\n",
        "        model.eval()\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            val_loss, correct_preds, num_examples = 0., 0, 0\n",
        "\n",
        "            for features, targets in val_loader:\n",
        "                features = features.to(device)\n",
        "                targets = targets.to(device)\n",
        "\n",
        "                outputs = model(features)\n",
        "\n",
        "                loss = F.cross_entropy(outputs, targets, reduction='sum')\n",
        "\n",
        "                val_loss += loss\n",
        "\n",
        "                _, predicted_labels = torch.max(outputs, 1)\n",
        "\n",
        "                correct_preds += (predicted_labels == targets).sum()\n",
        "\n",
        "                num_examples += targets.size(0)\n",
        "\n",
        "            val_loss = val_loss / num_examples\n",
        "            \n",
        "            val_acc = correct_preds.float() / num_examples * 100\n",
        "\n",
        "            print(f\"\\nVal Loss: {val_loss:.3f} | Val Accuracy: {val_acc:.3f}\\n\")\n",
        "\n",
        "            val_losses.append(val_loss)\n",
        "            val_accs.append(val_acc)\n",
        "\n",
        "            if not best_val_loss or val_loss < best_val_loss:\n",
        "                best_val_loss = val_loss\n",
        "                \n",
        "                counter = 0\n",
        "\n",
        "            else:\n",
        "                counter += 1\n",
        "\n",
        "                if counter == patience:\n",
        "                    print(f\"Early stopping at epoch {epoch + 1}!\")\n",
        "                    \n",
        "                    break\n",
        "\n",
        "\n",
        "        print(f\"Time elapsed: {((time.time() - start_time) / 60):.2f} min\\n\\n\")\n",
        "\n",
        "    print(f\"Total Training Time: {((time.time() - start_time) / 60):.2f} min\\n\")\n",
        "\n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        correct_preds, num_examples = 0, 0\n",
        "\n",
        "        for features, targets in test_loader:\n",
        "            features = features.to(device)\n",
        "            targets = targets.to(device)\n",
        "\n",
        "            outputs = model(features)\n",
        "\n",
        "            _, predicted_labels = torch.max(outputs, 1)\n",
        "\n",
        "            correct_preds += (predicted_labels == targets).sum()\n",
        "\n",
        "            num_examples += targets.size(0)\n",
        "        \n",
        "        test_acc = correct_preds.float() / num_examples * 100\n",
        "\n",
        "        print(f\"Test accuracy: {test_acc:.2f}%\")\n",
        "    \n",
        "    return train_losses, val_losses, train_accs, val_accs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "bENGftjmV7fB"
      },
      "outputs": [],
      "source": [
        "num_classes = 10\n",
        "learning_rate = 0.001\n",
        "num_epochs = 5\n",
        "mini_batch_size = 72"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJbTqKFEFurS",
        "outputId": "ac41224a-04fc-4101-ef5c-92d9678a69d7"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                          std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "dataset = datasets.CIFAR10(root='./data', download=True, transform=transform)\n",
        "\n",
        "train_size = int(0.98 * len(dataset))\n",
        "val_size = int(0.01 * len(dataset))\n",
        "test_size = len(dataset) - train_size - val_size\n",
        "\n",
        "train_set, val_set, test_set = torch.utils.data.random_split(dataset, [train_size, val_size, test_size])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_set,\n",
        "                                          batch_size=mini_batch_size,\n",
        "                                          shuffle=True,\n",
        "                                          num_workers=2,)\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(val_set,\n",
        "                                        batch_size=mini_batch_size,\n",
        "                                        shuffle=False,\n",
        "                                        num_workers=2,)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_set,\n",
        "                                         batch_size=mini_batch_size,\n",
        "                                         shuffle=False,\n",
        "                                         num_workers=2,)\n",
        "\n",
        "for images, labels in train_loader:\n",
        "    print('Image batch dimensions:', images.shape)\n",
        "    print('Image label dimensions:', labels.shape)\n",
        "\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "chBhviSSFurU"
      },
      "outputs": [],
      "source": [
        "model = VGG16()\n",
        "model = model.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "train_losses, val_losses, train_accs, val_accs = train_model(model, device, train_loader, val_loader, test_loader, num_epochs, optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "gihhZ-jElWCx",
        "outputId": "c1f49424-97b3-44db-fc19-d8df80f25a04"
      },
      "outputs": [],
      "source": [
        "val_losses_cpu = torch.Tensor(val_losses).to('cpu')\n",
        "val_accs_cpu = torch.Tensor(val_accs).to('cpu')\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
        "\n",
        "ax1.plot(train_losses, label='Train Loss')\n",
        "ax1.plot(val_losses_cpu, label='Val Loss')\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_ylabel('Loss')\n",
        "ax1.legend()\n",
        "ax1.set_title('Loss')\n",
        "\n",
        "ax2.plot(train_accs, label='Train Accuracy')\n",
        "ax2.plot(val_accs_cpu, label='Val Accuracy')\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_ylabel('Accuracy')\n",
        "ax1.legend()\n",
        "ax1.set_title('Accuracy')\n",
        "\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
