{"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport time\nimport numpy as np\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt\nimport seaborn as sn\nimport pandas as pd\n\nfrom torchvision import datasets\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader\nfrom sklearn.metrics import confusion_matrix","metadata":{"id":"T0JhngkfFurR","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache() \n\nif torch.cuda.is_available():\n    torch.backends.cudnn.deterministic = True\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint('Device:', device)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v69C54SlV5ub","outputId":"b0909b8a-f02c-4012-bed1-f7ebe62b712e","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class LightVGG(nn.Module):\n    def __init__(self, num_classes=10):\n        super(LightVGG, self).__init__()\n\n        self.features = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n            nn.BatchNorm2d(num_features=64),\n            nn.ReLU(inplace=True),\n\n            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n            nn.BatchNorm2d(num_features=64),\n            nn.ReLU(inplace=True),\n\n            nn.MaxPool2d(kernel_size=2, stride=2),\n\n            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n            nn.BatchNorm2d(num_features=128),\n            nn.ReLU(inplace=True),\n\n            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n            nn.BatchNorm2d(num_features=128),\n            nn.ReLU(inplace=True),\n\n            nn.MaxPool2d(kernel_size=2, stride=2),\n\n            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n            nn.BatchNorm2d(num_features=256),\n            nn.ReLU(inplace=True),\n\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.BatchNorm2d(num_features=256),\n            nn.ReLU(inplace=True),\n\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        )\n\n        self.classifier = nn.Sequential(\n            nn.Linear(256 * 4 * 4, 512),\n            nn.BatchNorm2d(512),\n            nn.ReLU(inplace=True),\n\n            nn.Dropout(p=0.5),\n\n            nn.Linear(512, num_classes),\n        )\n\n    def forward(self, x):\n        x = self.features(x)\n\n        x = x.view(x.size(0), -1)\n\n        x = self.classifier(x)\n\n        return x","metadata":{"id":"ub0ok_w6FurT","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model(model, device, train_loader, val_loader, num_epochs, optimizer, patience):\n    start_time = time.time()\n\n    train_losses = []\n    val_losses = []\n\n    train_accs = []\n    val_accs = []\n\n    counter = 0\n    best_val_loss = 0\n\n    for epoch in range(num_epochs):\n        model.train()\n\n        running_loss = 0.0\n        running_correct = 0\n\n        for batch_idx, (features, targets) in enumerate(train_loader):\n            features = features.to(device)\n            targets = targets.to(device)\n\n            outputs = model(features)\n            loss = F.cross_entropy(outputs, targets)\n            optimizer.zero_grad()\n\n            loss.backward()\n\n            optimizer.step()\n\n            running_loss += loss.item()\n            _, predicted_labels = torch.max(outputs, 1)\n            running_correct += (predicted_labels == targets).sum().item()\n\n            if not batch_idx % 50:\n                print(f\"Epoch: {epoch+1:02d}/{num_epochs:02d} | Mini-Batch {batch_idx:03d}/{len(train_loader):03d} | Loss: {loss:.4f}\")\n\n        train_loss = running_loss / len(train_loader)\n        train_acc = running_correct / len(train_loader)\n\n        train_losses.append(train_loss)\n        train_accs.append(train_acc)\n\n        model.eval()\n\n        with torch.no_grad():\n            val_loss, correct_preds, num_examples = 0., 0, 0\n\n            for features, targets in val_loader:\n                features = features.to(device)\n                targets = targets.to(device)\n\n                outputs = model(features)\n\n                loss = F.cross_entropy(outputs, targets, reduction='sum')\n\n                val_loss += loss\n\n                _, predicted_labels = torch.max(outputs, 1)\n\n                correct_preds += (predicted_labels == targets).sum()\n\n                num_examples += targets.size(0)\n\n            val_loss = val_loss / num_examples\n\n            val_acc = correct_preds.float() / num_examples * 100\n\n            print(f\"\\nVal Loss: {val_loss:.3f} | Val Accuracy: {val_acc:.3f}\\n\")\n\n            val_losses.append(val_loss)\n            val_accs.append(val_acc)\n\n            if not best_val_loss or val_loss < best_val_loss:\n                best_val_loss = val_loss\n\n                counter = 0\n\n            else:\n                counter += 1\n\n                if counter == patience:\n                    print(f\"Early stopping at epoch {epoch + 1}!\")\n\n                    break\n\n\n        print(f\"Time elapsed: {((time.time() - start_time) / 60):.2f} min\\n\\n\")\n\n    print(f\"Total Training Time: {((time.time() - start_time) / 60):.2f} min\\n\")\n\n\n    return train_losses, val_losses, train_accs, val_accs","metadata":{"id":"72WH4rzZVvJH","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def model_test(model, device, test_loader):\n    model.eval()\n\n    with torch.no_grad():\n        correct_preds, num_examples = 0, 0\n\n        for features, targets in test_loader:\n            features = features.to(device)\n            targets = targets.to(device)\n\n            outputs = model(features)\n\n            _, predicted_labels = torch.max(outputs, 1)\n\n            correct_preds += (predicted_labels == targets).sum()\n\n            num_examples += targets.size(0)\n\n        test_acc = correct_preds.float() / num_examples * 100\n\n        print(f\"Test accuracy: {test_acc:.2f}%\")","metadata":{"id":"Gdpi4TthzcTO","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def draw_confusion_matrix(model, device, classes, test_loader):\n    model.eval()\n\n    preds = []\n    truths = []\n\n    with torch.no_grad():\n        for features, targets in test_loader:\n            features = features.to(device)\n            targets = targets.to(device)\n\n            outputs = model(features)\n\n            outputs = (torch.max(torch.exp(outputs), 1)[1]).data.cpu().numpy()\n            preds.extend(outputs)\n\n            truths.extend(targets.data.cpu().numpy())\n\n    cf_matrix = confusion_matrix(truths, preds)\n\n    df_cm = pd.DataFrame(cf_matrix / np.sum(cf_matrix, axis=1)[:, None],\n                         index = [i for i in classes],\n                         columns = [i for i in classes])\n\n    plt.figure(figsize = (12,7))\n\n    sn.heatmap(df_cm, annot=True)\n\n","metadata":{"id":"5zmDvxX10PEO","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def draw_cross_validation(train_losses, val_losses, train_accs, val_accs):\n    val_losses_cpu = torch.Tensor(val_losses).cpu()\n    val_accs_cpu = torch.Tensor(val_accs).cpu()\n\n    fig, (ax1, ax2) = plt.subplots(1, 2)\n\n    ax1.plot(train_losses, label='Train Loss')\n    ax1.plot(val_losses_cpu, label='Val Loss')\n    ax1.set_xlabel('Epoch')\n    ax1.set_ylabel('Loss')\n    ax1.legend()\n\n    ax2.plot(train_accs, label='Train Accuracy')\n    ax2.plot(val_accs_cpu, label='Val Accuracy')\n    ax2.set_xlabel('Epoch')\n    ax2.set_ylabel('Accuracy')\n    ax2.legend()\n\n    plt.show()","metadata":{"id":"gihhZ-jElWCx","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_classes = 10\nlearning_rate = 0.001\nnum_epochs = 25\nbatch_size = 64\npatience = 5","metadata":{"id":"bENGftjmV7fB","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                          std=[0.229, 0.224, 0.225])\n])\n\ndataset = datasets.CIFAR10(root='./data', download=True, transform=transform)\n\ntrain_size = int(0.9 * len(dataset))\nval_size = int(0.05 * len(dataset))\ntest_size = len(dataset) - train_size - val_size\n\ntrain_set, val_set, test_set = torch.utils.data.random_split(dataset, [train_size, val_size, test_size])\n\ntrain_loader = torch.utils.data.DataLoader(train_set,\n                                          batch_size=batch_size,\n                                          shuffle=True,\n                                          num_workers=2)\n\nval_loader = torch.utils.data.DataLoader(val_set,\n                                        batch_size=batch_size,\n                                        shuffle=False,\n                                        num_workers=2)\n\ntest_loader = torch.utils.data.DataLoader(test_set,\n                                         batch_size=batch_size,\n                                         shuffle=False,\n                                         num_workers=2)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wJbTqKFEFurS","outputId":"ec32eb2d-e3bc-42fb-8bb4-657d279ed19c","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = LightVGG()\nmodel = model.to(device)\n\noptimizer = torch.optim.Adam(model.parameters())\n\ntrain_losses, val_losses, train_accs, val_accs = train_model(model, device, train_loader, val_loader, num_epochs, optimizer, patience)\n\nmodel_test(model, device, test_loader)","metadata":{"id":"chBhviSSFurU","colab":{"base_uri":"https://localhost:8080/"},"outputId":"412e2a56-65df-4672-e9ef-2860321a4c14","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"draw_cross_validation(train_losses, val_losses, train_accs, val_accs)","metadata":{"id":"19iVp_qs3OuQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes = (\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\")\n\ndraw_confusion_matrix(model, device, classes, test_loader)","metadata":{"id":"T-xMDfI22Kk3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model, \"vgg16_cifar10.pt\")","metadata":{"id":"lGzWwPyQ3zk3"},"execution_count":null,"outputs":[]}]}