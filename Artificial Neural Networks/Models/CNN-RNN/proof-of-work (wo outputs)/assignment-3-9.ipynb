{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Importing Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-28T19:05:24.518560Z","iopub.status.busy":"2024-01-28T19:05:24.518188Z","iopub.status.idle":"2024-01-28T19:05:47.377739Z","shell.execute_reply":"2024-01-28T19:05:47.376867Z","shell.execute_reply.started":"2024-01-28T19:05:24.518527Z"},"trusted":true},"outputs":[],"source":["!pip install torchsummary\n","\n","import os\n","import math\n","import spacy\n","import torch\n","import numpy as np\n","import pandas as pd\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torchvision.transforms as T\n","\n","from PIL import Image\n","from torch import nn\n","from torchsummary import summary\n","from matplotlib import pyplot as plt\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","from torch.nn.utils.rnn import pad_sequence\n","from torchvision.models import vgg16, VGG16_Weights\n","from nltk.translate.bleu_score import sentence_bleu\n","\n","spacy_eng = spacy.load(\"en_core_web_sm\")"]},{"cell_type":"markdown","metadata":{},"source":["### Setting the Device"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-28T19:05:54.258904Z","iopub.status.busy":"2024-01-28T19:05:54.257632Z","iopub.status.idle":"2024-01-28T19:05:54.265250Z","shell.execute_reply":"2024-01-28T19:05:54.264041Z","shell.execute_reply.started":"2024-01-28T19:05:54.258859Z"},"trusted":true},"outputs":[],"source":["if torch.cuda.is_available():\n","    torch.backends.cudnn.deterministic = True\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","print('Device:', device)"]},{"cell_type":"markdown","metadata":{},"source":["# Preparing the Flikr30k Dataset\n","### Preparing the Vocabulary"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-01-28T19:05:54.660935Z","iopub.status.busy":"2024-01-28T19:05:54.660495Z","iopub.status.idle":"2024-01-28T19:05:54.671259Z","shell.execute_reply":"2024-01-28T19:05:54.670029Z","shell.execute_reply.started":"2024-01-28T19:05:54.660899Z"},"trusted":true},"outputs":[],"source":["class Vocabulary:\n","    def __init__(self, freq_threshold):\n","        self.freq_threshold = freq_threshold\n","        self.itos = {0: \"<PAD>\", 1: \"<SOS>\", 2: \"<EOS>\", 3: \"<UNK>\"}\n","        self.stoi = {v: k for k,v in self.itos.items()}\n","    \n","    def __len__(self):\n","        return len(self.itos)\n","  \n","    def build_vocab(self, sentence_list):\n","        freqs = {}\n","        idx = 4\n","\n","        for sentence in sentence_list:\n","            sentence = str(sentence)\n","\n","            for word in self.tokenize(sentence):\n","                if word not in freqs:\n","                    freqs[word] = 1\n","                    \n","                else:\n","                    freqs[word] += 1\n","\n","                if freqs[word] == self.freq_threshold:\n","                    self.itos[idx] = word\n","                    self.stoi[word] = idx\n","                    \n","                    idx += 1\n","\n","    def numericalize(self, sentence):\n","        tokens = self.tokenize(sentence)\n","        result = []\n","\n","        for token in tokens:\n","            if token in self.stoi:\n","                result.append(self.stoi[token])\n","            else:\n","                result.append(self.stoi[\"<UNK>\"])\n","\n","        return result\n","    \n","    @staticmethod\n","    def tokenize(sentence):\n","        return [token.text.lower() for token in spacy_eng.tokenizer(str(sentence))]"]},{"cell_type":"markdown","metadata":{},"source":["### Defining a Custom Dataset"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-01-28T19:05:55.208540Z","iopub.status.busy":"2024-01-28T19:05:55.208141Z","iopub.status.idle":"2024-01-28T19:05:55.218846Z","shell.execute_reply":"2024-01-28T19:05:55.217873Z","shell.execute_reply.started":"2024-01-28T19:05:55.208508Z"},"trusted":true},"outputs":[],"source":["class Flickr(Dataset):\n","    def __init__(self, root_dir, caption_path, transform, freq_threshold=5):\n","        self.freq_threshold = freq_threshold\n","        self.transform = transform\n","        self.root_dir = root_dir\n","    \n","        self.df = pd.read_csv(caption_path, delimiter='|')\n","        \n","        self.images = self.df['image_name']\n","        self.captions = self.df[' comment']\n","        \n","        self.vocab = Vocabulary(freq_threshold)\n","        \n","        self.vocab.build_vocab(self.captions.tolist())\n","        \n","    def __len__(self):\n","        return len(self.df)\n","    \n","    def __getitem__(self, index):\n","        image = self.images[index]\n","        caption = self.captions[index]\n","        \n","        image = Image.open(os.path.join(self.root_dir, image)).convert(\"RGB\")\n","        \n","        image = self.transform(image)\n","        \n","        numericalized_caption = [self.vocab.stoi[\"<SOS>\"]]\n","        \n","        numericalized_caption += self.vocab.numericalize(caption)\n","        \n","        numericalized_caption.append(self.vocab.stoi[\"<EOS>\"])\n","        \n","        return image, torch.tensor(numericalized_caption)\n","    \n","    def get_label(self, index):\n","        image, caption = self[index]\n","    \n","        label = [self.vocab.itos[token] for token in caption.tolist()]\n","\n","        eos_index = label.index('<EOS>')\n","\n","        label = label[1: eos_index]\n","\n","        return ' '.join(label)\n","    \n","    def to_list(self):\n","        return [self.get_label(idx) for idx in range(len(self))]\n","        "]},{"cell_type":"markdown","metadata":{},"source":["### Defining a Custom Caption Collat for Padding"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-01-28T19:05:55.968052Z","iopub.status.busy":"2024-01-28T19:05:55.967362Z","iopub.status.idle":"2024-01-28T19:05:55.974062Z","shell.execute_reply":"2024-01-28T19:05:55.973168Z","shell.execute_reply.started":"2024-01-28T19:05:55.968014Z"},"trusted":true},"outputs":[],"source":["class CapCollat:\n","    def __init__(self, pad_seq, batch_first=False):\n","        self.pad_seq = pad_seq\n","        self.batch_first = batch_first\n","  \n","    def __call__(self, batch):\n","        imgs = [itm[0].unsqueeze(0) for itm in batch]\n","        imgs = torch.cat(imgs, dim=0)\n","\n","        target_caps = [itm[1] for itm in batch]\n","        target_caps = pad_sequence(target_caps, batch_first=self.batch_first,\n","                                   padding_value=self.pad_seq)\n","        \n","        return imgs, target_caps"]},{"cell_type":"markdown","metadata":{},"source":["### Loading and Testing the Dataset "]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-01-28T19:05:58.707512Z","iopub.status.busy":"2024-01-28T19:05:58.706574Z","iopub.status.idle":"2024-01-28T19:06:31.253760Z","shell.execute_reply":"2024-01-28T19:06:31.252735Z","shell.execute_reply.started":"2024-01-28T19:05:58.707469Z"},"trusted":true},"outputs":[],"source":["root_folder = \"/kaggle/input/flickr-image-dataset/flickr30k_images/flickr30k_images/\"\n","csv_file = \"/kaggle/input/flickr-image-dataset/flickr30k_images/results.csv\"\n","\n","transform = T.Compose([\n","        T.Resize((256, 256), interpolation=T.InterpolationMode.BILINEAR),\n","        T.CenterCrop((224, 224)),\n","        T.ToTensor(),\n","        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])\n","\n","batch_size = 32\n","num_workers = 2\n","batch_first = True\n","pin_memory = True\n","dataset = Flickr(root_folder, csv_file, transform)\n","pad_idx = dataset.vocab.stoi[\"<PAD>\"]\n","\n","data_size = len(dataset)\n","train_size = int(0.9 * data_size)\n","val_size = data_size - train_size\n","\n","train_set, val_set = torch.utils.data.Subset(dataset, range(0, train_size)), torch.utils.data.Subset(dataset, range(train_size, data_size))\n","\n","train_loader = DataLoader(train_set,\n","                            batch_size=batch_size,\n","                            pin_memory=pin_memory,\n","                            num_workers=num_workers,\n","                            shuffle=True,\n","                            collate_fn=CapCollat(pad_seq=pad_idx, batch_first=batch_first))\n","\n","val_loader = DataLoader(val_set,\n","                            batch_size=batch_size,\n","                            pin_memory=pin_memory,\n","                            num_workers=num_workers,\n","                            shuffle=False,\n","                            collate_fn=CapCollat(pad_seq=pad_idx, batch_first=batch_first))"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-01-28T19:07:18.612178Z","iopub.status.busy":"2024-01-28T19:07:18.611489Z","iopub.status.idle":"2024-01-28T19:31:32.332009Z","shell.execute_reply":"2024-01-28T19:31:32.330894Z","shell.execute_reply.started":"2024-01-28T19:07:18.612138Z"},"trusted":true},"outputs":[],"source":["val_set_start = data_size - val_size - 1\n","val_set_end = data_size - 1\n","\n","all_labels = dataset.to_list()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-28T19:38:04.442605Z","iopub.status.busy":"2024-01-28T19:38:04.442138Z","iopub.status.idle":"2024-01-28T19:38:07.647154Z","shell.execute_reply":"2024-01-28T19:38:07.646063Z","shell.execute_reply.started":"2024-01-28T19:38:04.442569Z"},"trusted":true},"outputs":[],"source":["for idx in range(0, 100, 10):\n","    image, _ = dataset[idx + val_size]\n","    \n","    label = all_labels[idx + val_size]\n","\n","    image = image.permute(1,2,0)\n","    \n","    plt.imshow(image)\n","    plt.title(label)\n","\n","    plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# Pre-Trained CNN Encoder: VGG16 "]},{"cell_type":"code","execution_count":52,"metadata":{"execution":{"iopub.execute_input":"2024-01-28T20:51:07.818912Z","iopub.status.busy":"2024-01-28T20:51:07.818374Z","iopub.status.idle":"2024-01-28T20:51:07.827130Z","shell.execute_reply":"2024-01-28T20:51:07.825890Z","shell.execute_reply.started":"2024-01-28T20:51:07.818873Z"},"trusted":true},"outputs":[],"source":["class EncoderCNN(nn.Module):\n","    def __init__(self, embed_size):\n","        super(EncoderCNN, self).__init__()\n","\n","        vgg = vgg16(weights=VGG16_Weights.DEFAULT)\n","        feature_extractor = list(vgg.children())[:-1]\n","        \n","        for param in vgg.parameters():\n","            param.requires_grad = False\n","            \n","        embedding_layer = nn.Linear(512 * 7 * 7, embed_size)\n","\n","        self.vgg = nn.Sequential(*feature_extractor,\n","                                 nn.Flatten(),\n","                                 embedding_layer)\n","       \n","    def forward(self, image):\n","        encoded_image = self.vgg(image)\n","  \n","        return encoded_image"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-28T20:51:09.204573Z","iopub.status.busy":"2024-01-28T20:51:09.203590Z","iopub.status.idle":"2024-01-28T20:51:11.825662Z","shell.execute_reply":"2024-01-28T20:51:11.824345Z","shell.execute_reply.started":"2024-01-28T20:51:09.204516Z"},"trusted":true},"outputs":[],"source":["summary(EncoderCNN(256), (3, 224, 224))"]},{"cell_type":"markdown","metadata":{},"source":["# RNN Decoder: Vanilla RNN Module"]},{"cell_type":"code","execution_count":54,"metadata":{"execution":{"iopub.execute_input":"2024-01-28T20:51:16.332915Z","iopub.status.busy":"2024-01-28T20:51:16.332433Z","iopub.status.idle":"2024-01-28T20:51:16.341141Z","shell.execute_reply":"2024-01-28T20:51:16.339815Z","shell.execute_reply.started":"2024-01-28T20:51:16.332878Z"},"trusted":true},"outputs":[],"source":["class DecoderRNN(nn.Module):\n","    def __init__(self, embed_size, vocab_size, hidden_size, num_layers):\n","        super(DecoderRNN, self).__init__()\n","\n","        self.embedding = nn.Embedding(vocab_size, embed_size)\n","        self.rnn = nn.RNN(embed_size, hidden_size, num_layers, batch_first=True)\n","        self.linear = nn.Linear(hidden_size, vocab_size)\n","    \n","    def forward(self, features, caption):\n","        embeddings = self.embedding(caption)\n","        embeddings = torch.cat((features.unsqueeze(dim=1),embeddings), 1)\n","        output, hidden = self.rnn(embeddings)\n","        output = self.linear(output)\n","\n","        return output"]},{"cell_type":"code","execution_count":59,"metadata":{"execution":{"iopub.execute_input":"2024-01-28T20:52:16.806157Z","iopub.status.busy":"2024-01-28T20:52:16.805686Z","iopub.status.idle":"2024-01-28T20:52:16.816601Z","shell.execute_reply":"2024-01-28T20:52:16.815190Z","shell.execute_reply.started":"2024-01-28T20:52:16.806113Z"},"trusted":true},"outputs":[],"source":["class Hybrid(nn.Module):\n","    def __init__(self, embed_size, vocab_size, hidden_size, num_layers):\n","        super(Hybrid, self).__init__()\n","        \n","        self.encoderCNN = EncoderCNN(embed_size)\n","        self.decoderRNN = DecoderRNN(embed_size, vocab_size, hidden_size, num_layers)\n","    \n","    def forward(self, images, caption):\n","        x = self.encoderCNN(images)\n","        x = self.decoderRNN(x, caption)\n","        \n","        return x\n","    \n","    def captionImage(self, image, vocabulary, maxlength=50):\n","        result_caption = []\n","        \n","        with torch.no_grad():\n","            x = self.encoderCNN(image).unsqueeze(0)\n","            states = None\n","            \n","            for _ in range(maxlength):\n","                hiddens, states = self.decoderRNN.lstm(x, states)\n","                output = self.decoderRNN.linear(hiddens.squeeze(0))\n","                predicted = output.argmax(1)\n","                print(predicted.shape)\n","                result_caption.append(predicted.item())\n","                x = self.decoderRNN.embedding(output).unsqueeze(0)\n","                \n","                if vocabulary.itos[predicted.item()] == \"<EOS>\":\n","                    break\n","                \n","        return [vocabulary.itos[i] for i in result_caption]"]},{"cell_type":"markdown","metadata":{},"source":["# Training and Evaluating the Image Captioning Model: VGG16 + Multi-layer Vanilla RNN"]},{"cell_type":"markdown","metadata":{},"source":["### Setting Hyperparameters"]},{"cell_type":"code","execution_count":60,"metadata":{"execution":{"iopub.execute_input":"2024-01-28T20:52:25.362974Z","iopub.status.busy":"2024-01-28T20:52:25.362494Z","iopub.status.idle":"2024-01-28T20:52:25.368556Z","shell.execute_reply":"2024-01-28T20:52:25.367276Z","shell.execute_reply.started":"2024-01-28T20:52:25.362935Z"},"trusted":true},"outputs":[],"source":["num_epochs = 10\n","freq_threshold = 5\n","enc_dim = 2048\n","embed_size = 256\n","hidden_size = 512\n","num_layers = 1\n","learning_rate = 3e-4"]},{"cell_type":"markdown","metadata":{},"source":["### Setting the Vocabulary"]},{"cell_type":"code","execution_count":61,"metadata":{"execution":{"iopub.execute_input":"2024-01-28T20:52:26.792133Z","iopub.status.busy":"2024-01-28T20:52:26.791672Z","iopub.status.idle":"2024-01-28T20:52:26.797572Z","shell.execute_reply":"2024-01-28T20:52:26.796320Z","shell.execute_reply.started":"2024-01-28T20:52:26.792095Z"},"trusted":true},"outputs":[],"source":["vocab = dataset.vocab\n","vocab_size = len(vocab)"]},{"cell_type":"markdown","metadata":{},"source":["### Configuring Models"]},{"cell_type":"code","execution_count":62,"metadata":{"execution":{"iopub.execute_input":"2024-01-28T20:52:28.509391Z","iopub.status.busy":"2024-01-28T20:52:28.508960Z","iopub.status.idle":"2024-01-28T20:52:31.297453Z","shell.execute_reply":"2024-01-28T20:52:31.296280Z","shell.execute_reply.started":"2024-01-28T20:52:28.509359Z"},"trusted":true},"outputs":[],"source":["criterion = nn.CrossEntropyLoss(ignore_index = vocab.stoi[\"<PAD>\"])\n","\n","model = Hybrid(embed_size, hidden_size, vocab_size, num_layers).to(device=device)\n","\n","optimizer = optim.Adam(model.parameters(), lr = learning_rate)"]},{"cell_type":"markdown","metadata":{},"source":["### Training Models"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-28T20:52:35.214336Z","iopub.status.busy":"2024-01-28T20:52:35.213880Z","iopub.status.idle":"2024-01-28T20:52:47.959421Z","shell.execute_reply":"2024-01-28T20:52:47.957956Z","shell.execute_reply.started":"2024-01-28T20:52:35.214299Z"},"trusted":true},"outputs":[],"source":["!pip install pycocoevalcap"]},{"cell_type":"code","execution_count":64,"metadata":{"execution":{"iopub.execute_input":"2024-01-28T20:52:51.054140Z","iopub.status.busy":"2024-01-28T20:52:51.053315Z","iopub.status.idle":"2024-01-28T20:52:51.073279Z","shell.execute_reply":"2024-01-28T20:52:51.071670Z","shell.execute_reply.started":"2024-01-28T20:52:51.054094Z"},"trusted":true},"outputs":[],"source":["from pycocoevalcap.bleu.bleu import Bleu\n","from pycocoevalcap.meteor.meteor import Meteor\n","from pycocoevalcap.rouge.rouge import Rouge\n","from pycocoevalcap.cider.cider import Cider\n","\n","class Scorer():\n","    def __init__(self,ref,gt):\n","        self.ref = ref\n","        self.gt = gt\n","\n","        self.word_based_scorers = [\n","            (Bleu(4), [\"Bleu_1\", \"Bleu_2\", \"Bleu_3\", \"Bleu_4\"]),\n","            (Meteor(),\"METEOR\"),\n","            (Rouge(), \"ROUGE_L\"),\n","            (Cider(), \"CIDEr\"),\n","            ]\n","\n","    def compute_scores(self):\n","        total_scores = {\n","            \"Bleu1\":[],\n","            \"Bleu2\":[],\n","            \"Bleu3\":[],\n","            \"Bleu4\":[],\n","            \"METEOR\":[],\n","            \"ROUGE_L\":[],\n","            \"CIDEr\":[],\n","        }\n","\n","        for scorer, method in self.word_based_scorers:\n","            score, scores = scorer.compute_score(self.ref, self.gt)\n","    \n","            if type(method) == list:\n","                total_scores[\"Bleu1\"].append(score[0])\n","                total_scores[\"Bleu2\"].append(score[1])\n","                total_scores[\"Bleu3\"].append(score[2])\n","                total_scores[\"Bleu4\"].append(score[3])\n","\n","            else:\n","                total_scores[method].append(score)\n","\n","        return total_scores\n","    \n","    def compute_scores_iterative(self):\n","        total_scores = {\n","            \"Bleu1\":[],\n","            \"Bleu2\":[],\n","            \"Bleu3\":[],\n","            \"Bleu4\":[],\n","            \"METEOR\":[],\n","            \"ROUGE_L\":[],\n","            \"CIDEr\":[],\n","            \"SPICE\":[]\n","        \n","        }\n","\n","        for key in self.ref:\n","            curr_ref = {key:self.ref[key]}\n","            curr_gt = {key:self.gt[key]}\n","\n","            for scorer, method in self.word_based_scorers:\n","                score, _ = scorer.compute_score(curr_ref, curr_gt)\n","                if type(method) == list:\n","                    total_scores[\"Bleu1\"].append(score[0])\n","                    total_scores[\"Bleu2\"].append(score[1])\n","                    total_scores[\"Bleu3\"].append(score[2])\n","                    total_scores[\"Bleu4\"].append(score[3])\n","\n","                else:\n","                    total_scores[method].append(score)\n","\n","        return total_scores"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-28T20:54:41.021773Z","iopub.status.busy":"2024-01-28T20:54:41.021240Z","iopub.status.idle":"2024-01-28T20:54:52.651480Z","shell.execute_reply":"2024-01-28T20:54:52.649591Z","shell.execute_reply.started":"2024-01-28T20:54:41.021721Z"},"trusted":true},"outputs":[],"source":["train_losses = list()\n","val_losses = list()\n","\n","cumulative_bleu_scores = list()\n","\n","cider_scores = list()\n","\n","meteor_scores = list()\n","\n","rougel_scores = list()\n","\n","bleu1_scores = list()\n","bleu2_scores = list()\n","bleu3_scores = list()\n","bleu4_scores = list()\n","\n","val_iter = iter(val_loader)\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","\n","    for batch_idx, (images, captions) in enumerate(train_loader):\n","        images = images.to(device)\n","        captions = captions.to(device)\n","        \n","        train_score = model(images, captions[:-1])\n","\n","        optimizer.zero_grad()\n","        \n","        train_loss = criterion(train_score.reshape(-1, train_score.shape[2]), captions.reshape(-1))\n","        train_losses.append(train_loss.item())\n","        \n","        train_loss.backward()\n","        optimizer.step()\n","\n","    with torch.no_grad():\n","        model.eval()\n","\n","        idx = val_set_start\n","\n","        hyp = {}\n","        ref = {}\n","\n","        while idx <= val_set_end:\n","            if idx % batch_size == 0:\n","                batch = next(val_iter)\n","\n","            val_images, val_captions = batch\n","\n","            image, caption = val_images[idx % batch_size], val_captions[idx % batch_size]\n","\n","            image = image.to_device()\n","            caption = caption.to_device()\n","\n","            val_score = model(image, caption[: -1])\n","\n","            val_loss = criterion(val_score.reshape(-1, val_score.shape[2]), val_captions[1:].reshape(-1))\n","\n","            val_losses.append(val_loss.item())\n","\n","            val_pred = model.caption_image(image, vocab)\n","\n","            hyp[idx] = [' '.join(val_pred)]\n","\n","            label = all_labels[idx]\n","\n","            ref[idx] = label\n","\n","            cumulative_bleu_score = sentence_bleu(label, val_pred, weights=(0.25, 0.25, 0.25, 0.25))\n","            cumulative_bleu_scores.append(cumulative_bleu_score)\n","            \n","            idx += 1\n","            \n","        metrics = Scorer(ref, hyp).compute_scores()\n","    \n","        bleu1_scores.append(metrics['Bleu_1'])\n","        bleu2_scores.append(metrics['Bleu_2'])\n","        bleu3_scores.append(metrics['Bleu_3'])\n","        bleu4_scores.append(metrics['Bleu_4'])\n","\n","        cider_scores.append(metrics['CIDEr'])\n","\n","        rougel_scores.append(metrics['ROUGE_L'])\n","\n","        meteor_scores.append(metrics['METEOR'])\n","        \n","        print(f\"Epoch [{epoch+1}/{num_epochs}] Batch [{batch_idx+1}/{len(train_loader)}] | Training loss: {train_loss.item()} Validation loss: {val_loss.item()} | Cumulative BLEU Score: {cumulative_bleu_score} CIDEr Score: {metrics['CIDEr']} METEOR Score: {metrics['METEOR']} ROUGE_L: {metrics['ROUGE_L']} \\n\")\n","\n","# if batch_idx == (len(train_loader) - 1):\n","#     torch.save(model.state_dict(), f'/kaggle/working/encoder_{freq_threshold}_{batch_size}_{hidden_size}_{epoch+1}.pth')\n"]},{"cell_type":"markdown","metadata":{},"source":["### Plotting Losses and Scores"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.figure(0)\n","plt.plot(train_losses, label = 'Training loss')\n","plt.plot(val_losses, label = 'Validation loss')\n","plt.ylabel('Cross Entropy Loss')\n","plt.legend()\n","plt.savefig(f'/kaggle/working/{freq_threshold}_{batch_size}_{hidden_size}_{num_epochs}_losses.png')\n","\n","plt.figure(1)\n","plt.plot(bleu1_scores, label = 'BLEU 1')\n","plt.plot(bleu2_scores, label = 'BLEU 2')\n","plt.plot(bleu3_scores, label = 'BLEU 3')\n","plt.plot(bleu4_scores, label = 'BLEU 4')\n","plt.ylabel('BLEU Scores')\n","plt.legend()\n","plt.savefig(f'/kaggle/working/{freq_threshold}_{batch_size}_{hidden_size}_{num_epochs}_bleu_scores.png')\n","        \n","plt.figure(2)\n","plt.plot(cumulative_bleu_scores, label = 'Cumulative BLEU SCORE')\n","plt.plot(cider_scores, label = 'CIDEr SCORE')\n","plt.plot(meteor_scores, label = 'METEOR SCORE')\n","plt.plot(rougel_scores, label = 'ROUGE_L SCORE')\n","plt.ylabel('Scores')\n","plt.legend()\n","plt.savefig(f'/kaggle/working/{freq_threshold}_{batch_size}_{hidden_size}_{num_epochs}_scores.png')"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":31296,"sourceId":39911,"sourceType":"datasetVersion"}],"dockerImageVersionId":30635,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
